"""
Clean up PhishGuard project - remove redundant files and checkpoints.
"""
import os
import shutil
from pathlib import Path


def get_folder_size(path):
    """Calculate folder size in MB."""
    total = 0
    for entry in Path(path).rglob('*'):
        if entry.is_file():
            total += entry.stat().st_size
    return total / (1024 * 1024)


def main():
    print("="*70)
    print("ğŸ§¹ PHISHGUARD PROJECT CLEANUP")
    print("="*70)
    
    base_dir = Path("d:/projects/ISM_Showcases/phishguard")
    
    # Items to clean
    cleanup_items = []
    
    # 1. Find checkpoint directories
    print("\n1ï¸âƒ£ Scanning for training checkpoints...")
    checkpoint_dirs = list(base_dir.rglob("checkpoint-*"))
    if checkpoint_dirs:
        for checkpoint in checkpoint_dirs:
            size = get_folder_size(checkpoint)
            cleanup_items.append({
                'path': checkpoint,
                'type': 'checkpoint',
                'size_mb': size,
                'reason': 'Training checkpoint (no longer needed)'
            })
    
    # 2. Find redundant data files
    print("\n2ï¸âƒ£ Scanning for redundant data files...")
    data_dir = base_dir / "data"
    if data_dir.exists():
        data_files = {
            'phishing_emails.csv': 'Original small dataset',
            'processed_emails.csv': 'Intermediate processed file',
            'synthetic_emails.csv': 'Old synthetic data',
            'combined_training_data.csv': 'Intermediate combined file',
            'enhanced_training_data.csv': 'Intermediate enhanced file'
        }
        
        for filename, reason in data_files.items():
            filepath = data_dir / filename
            if filepath.exists():
                size = filepath.stat().st_size / (1024 * 1024)
                cleanup_items.append({
                    'path': filepath,
                    'type': 'data',
                    'size_mb': size,
                    'reason': reason
                })
    
    # 3. Find redundant scripts
    print("\n3ï¸âƒ£ Scanning for redundant scripts...")
    scripts_dir = base_dir / "scripts"
    redundant_scripts = {
        'download_more_data.py': 'Outdated data downloader',
        'train_roberta.py': 'Alternative training script (not using)',
        'preview_datasets.py': 'Testing script',
        'test_model.py': 'Duplicate of evaluate_model.py'
    }
    
    for filename, reason in redundant_scripts.items():
        filepath = scripts_dir / filename
        if filepath.exists():
            size = filepath.stat().st_size / (1024 * 1024)
            cleanup_items.append({
                'path': filepath,
                'type': 'script',
                'size_mb': size,
                'reason': reason
            })
    
    # 4. Find redundant documentation
    print("\n4ï¸âƒ£ Scanning for redundant documentation...")
    redundant_docs = {
        'HUGGINGFACE_DATASETS.md': 'Outdated dataset info',
        'DATA_COLLECTION_GUIDE.md': 'Superseded by DATA_SOURCES.md'
    }
    
    for filename, reason in redundant_docs.items():
        filepath = base_dir / filename
        if filepath.exists():
            size = filepath.stat().st_size / (1024 * 1024)
            cleanup_items.append({
                'path': filepath,
                'type': 'docs',
                'size_mb': size,
                'reason': reason
            })
    
    # Show cleanup plan
    if not cleanup_items:
        print("\nâœ¨ Project is already clean!")
        return
    
    print("\n" + "="*70)
    print("ğŸ“‹ CLEANUP PLAN")
    print("="*70)
    
    total_size = sum(item['size_mb'] for item in cleanup_items)
    
    by_type = {}
    for item in cleanup_items:
        item_type = item['type']
        if item_type not in by_type:
            by_type[item_type] = []
        by_type[item_type].append(item)
    
    for item_type, items in by_type.items():
        type_size = sum(i['size_mb'] for i in items)
        print(f"\nğŸ“ {item_type.upper()} ({len(items)} items, {type_size:.2f} MB)")
        for item in items:
            print(f"   â”œâ”€ {item['path'].name} ({item['size_mb']:.2f} MB)")
            print(f"   â”‚  {item['reason']}")
    
    print(f"\nğŸ’¾ Total space to free: {total_size:.2f} MB")
    
    # Confirm deletion
    print("\n" + "="*70)
    response = input("ğŸ—‘ï¸  Delete these files? (yes/no): ").strip().lower()
    
    if response != 'yes':
        print("\nâŒ Cleanup cancelled")
        return
    
    # Perform cleanup
    print("\nğŸ—‘ï¸  Deleting files...")
    deleted_count = 0
    freed_space = 0
    
    for item in cleanup_items:
        try:
            if item['path'].is_dir():
                shutil.rmtree(item['path'])
            else:
                item['path'].unlink()
            
            print(f"   âœ… Deleted: {item['path'].name}")
            deleted_count += 1
            freed_space += item['size_mb']
        
        except Exception as e:
            print(f"   âŒ Failed to delete {item['path'].name}: {e}")
    
    print("\n" + "="*70)
    print("âœ… CLEANUP COMPLETE")
    print("="*70)
    print(f"\nğŸ“Š Results:")
    print(f"   Files deleted: {deleted_count}/{len(cleanup_items)}")
    print(f"   Space freed: {freed_space:.2f} MB")
    
    # What to keep
    print("\n" + "="*70)
    print("ğŸ“¦ KEEPING (Core Project Files)")
    print("="*70)
    print("\nğŸ“‚ Data:")
    print("   âœ… large_training_data.csv - Main training dataset (29,256 emails)")
    print("\nğŸ“‚ Model:")
    print("   âœ… models/phishguard-model/ - Fine-tuned DistilRoBERTa (330MB)")
    print("\nğŸ“‚ Scripts:")
    print("   âœ… test_datasets.py - Verify HuggingFace datasets")
    print("   âœ… evaluate_model.py - Evaluate model performance")
    print("   âœ… generate_large_dataset.py - Generate synthetic data if needed")
    print("\nğŸ“‚ Source:")
    print("   âœ… src/train.py - Training script")
    print("   âœ… src/api/main.py - Production API")
    print("   âœ… src/utils/ - Preprocessing utilities")
    print("\nğŸ“‚ Config:")
    print("   âœ… requirements.txt, Dockerfile, docker-compose.yml")
    print("   âœ… README.md, TECHNICAL_EXPLANATION.md")
    
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    main()
